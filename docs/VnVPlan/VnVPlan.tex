\documentclass[12pt, titlepage]{article}

\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=blue,
    filecolor=black,
    linkcolor=red,
    urlcolor=blue
}
\usepackage[round]{natbib}

\begin{document}

\title{ System Verification and Validation Plan for Truss Tool} 
\author{Maryam Valian}
\date{\today}
	
\maketitle

\pagenumbering{roman}

\section{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
13-02-2023 & 1.0 & First Draft of VnV plan\\
14-0202023 & 1.1& Updating Test cases   \\
\bottomrule
\end{tabularx}

\newpage

\tableofcontents

\newpage

\section{Symbols, Abbreviations and Acronyms}

\renewcommand{\arraystretch}{1.2}
\begin{tabular}{l l} 
  \toprule		
  \textbf{symbol} & \textbf{description}\\
  \midrule 
  T & Test\\
  SRS & Software Requirements Specification\\
  FR & Functional Requirements\\
  NFR & Nonfunctional Requirements\\
  N/A & Not Applicable\\
  VnV & Verification and Validation\\
  
\bottomrule
\end{tabular}\\


\newpage
This document provides an overview of the Verification and Validation
 plan for Truss Tool. The general information is introduced in section 3. The verification plans and the test descriptions are explained in section 4 and section 5, respectively.
\pagenumbering{arabic}
\section{General Information}


\subsection{Summary}

In this document, we explain how Truss Tool is being tested. Truss Tool is software for truss analysis. Users can define a specific truss, by giving the exact location of the joints, members, supports and external forces.  Truss Tool calculates the reaction of the supports and internal forces. 

\subsection{Objectives}

For our project, the most important quality of the software is the correctness of the results. So our objective is to build confidence in the software's correctness and increase its reliability. Not only functional requirements will be tested, but also We will test nonfunctional requirements in Section 5. 

\subsection{Relevant Documentation}
\begin{itemize}
	\item 
	\href{https://github.com/Maryamvalian/project741/blob/main/docs/ProblemStatementAndGoals/ProblemStatement.pdf}{Problem
	 Statement}
	\item 
	\href{https://github.com/Maryamvalian/project741/blob/main/docs/SRS/SRS.pdf}{SRS} 
	\item \href{https://github.com/Maryamvalian/project741/blob/main/docs/VnVReport/VnVReport.pdf}{VnV
	 report}
\end{itemize}

\section{Plan}
In This section, we explain the VnV plan of the Truss Tool. Section \ref{VTeam} introduces VnV team members and their roles in the project's verification. Verification plans of SRS, design, VnV plan verification plan and implementation are covered in section \ref{SRSvplan}, section \ref{Sec_Design_verific}, and section \ref{Sec_implementation},\ref{Sec_VofVnV} respectively. Section \ref{} introduces the tools that are used for automated testing. Section \ref{} outlines the validation plan of the software.

\subsection{Verification and Validation Team} \label{VTeam}
This section lists VnV team members and describes the role of each member in the project's verification.
\begin{itemize}
\item {Maryam Valian reviews the whole project as the author.}
\item {Dr. Spencer Smith reviews the whole project as supervisor.}
\item{Lesley Wheat reviews the whole project as a domain expert.}
\item{Joachim de Fourestier reviews the VnV plan as a secondary reviewer.}
\item{Jason Balaci reviews the MIS as a secondary reviewer.}

\end{itemize}

\subsection{SRS Verification Plan} \label{SRSvplan}
The SRS will be reviewed by Dr. Spencer Smith and Lesely Wheat. Reviewers can give feedback and revision suggestions to the author by creating issues on GitHub. It is the author's responsibility to check the submitted issues regularly and make necessary modifications.

\subsection{Design Verification Plan} \label{Sec_Design_verific}

The design document MIS will be reviewed by Dr. Spencer Smith, Lesley Wheat and Jason Balaci. Reviewers can give feedback and revision suggestions to the author by creating issues on GitHub. It is the author's responsibility to check the submitted issues regularly and make necessary modifications.

\subsection{Verification and Validation Plan Verification Plan} \label{Sec_VofVnV}
The VnV plan document will be reviewed by Dr. Spencer Smith, Lesley Wheat and Joachim de Frostier. Reviewers can give feedback and revision suggestions to the author by creating issues on GitHub. It is the author's responsibility to check the submitted issues regularly and make necessary modifications.
\subsection{Implementation Verification Plan} \label{Sec_implementation}
The implementation of the software will be verified using several techniques involving manual or automated interactions. The software will be developed in Python programming language. The code evaluation will involve unit and system testing. The tools for the
evaluations will be mentioned in section \ref{sec_automat}. Furthermore, the test cases used in system and unit testing will be stated in sections \ref{sec_systest} and \ref{sec_unitest}, respectively.

\subsection{Automated Testing and Verification Tools} \label{sec_automat}
Truss Tool will be tested and verified by Pytest as an automated tool for unit testing and system testing. Automated testing will be implemented for individual units as well as the integrated system.

\subsection{Software Validation Plan}
 Validation is the process of comparing the outputs of models to experimental values. The validation of the Truss Tool will be done by comparing the outputs of the software to several outputs from an online tool called 2D-Truss Analysis developed by \cite{valdivia}. The Euclidean distance between both results from the two software will be reported as an error measurement for some cases. The euclidean distance formula will be calculated as follows:\\
\newline
$d\left( p,q\right)   = \sqrt {\sum _{i=1}^{n}  \left( q_{i}-p_{i}\right)^2 } $ \\
\newline
Where $p$ is the vector of internal forces from the Truss Tool and $q$ is the vector of internal forces from the 2D-Truss Analysis for a specific test case. 

\section{System Test Description} \label{sec_systest}
	
\subsection{Tests for Functional Requirements}
The functional requirements are described in the \href{https://github.com/Maryamvalian/project741/blob/main/docs/SRS/SRS.pdf}{SRS}. Truss Tool will detect invalid inputs and assure that the calculated outputs are correct. Testing R1 and R2 will be explained in the input verification section. R3 and R4 will be explained in the output verification test. 
\subsubsection{Input Verification}
The inputs will be tested to satisfy R1 and R2 from Truss Tool SRS. Specifically, this test will ensure values of the inputs align with the input constraints. Table \ref{tbl_tc} displays the inputs and outputs of test cases for the input constraints tests.
\begin{center}
 \begin{tabular}{|c|c c c c c| c |} 
 \hline
 &$N$&$J$&$M$&$F$&$\{S(p,r)\}$& \textbf{Output}\\ 
 \hline
 TC1-1 & 3& $\{(0,0),(1,1),(2,0)\}$ & $\{(1,2),(2,3),(1,3)\}$ &$\{(2,-50)\}$ & (1,3) & (25,25)(-35,-35,25) \\ 
 \hline
 TC2-1 & 10 & $\{(0,0),..,(2,0)\}$ & $\{(1,2),..,(1,3)\}$ &$\{(2,-50)\}$ & (1,3) & Exception: InputError \\ 
 \hline
  TC2-2 & 2 & $\{(0,0),(2,0)\}$ & $\{(1,2)\}$ &$\{(2,-50)\}$ & (1,2) & Exception: InputError \\ 
 \hline
 TC3-1 & 3& $\{(0,0),(1,1),(2,0)\}$ & $\{(1,2),(2,3),(1,3)\}$ &$\{(2,-36000)\}$ & (1,3) & Exception: InputError \\ 
 \hline
  TC3-2 & 3& $\{(0,0),(1,1),(2,0)\}$ & $\{(1,2),(2,3),(1,3)\}$ &$\{(2,36000)\}$ & (1,3) & Exception: InputError \\ 
 \hline
  TC4-1 & 3& $\{(0,0),(1,1),(2,0)\}$ & $\{(1,2),(2,3),(1,3)\}$ &$\{(2,-50)\}$ & (0,0) & Exception: InputError \\ 
 \hline
 TC4-2 & 3& $\{(0,0),(1,1),(2,0)\}$ & $\{(4,5),(9,3),(1,3)\}$ &$\{(2,-50)\}$ & (1,3) & Exception: InputError \\ 
 \hline
 TC4-3 & 3& $\{(0,0),(1,1),(2,0)\}$ & $\{(1,2),(2,3),(1,3)\}$ &$\{(4,-50)\}$ & (1,3) & Exception: InputError \\ 
 \hline
 TC4-4 & 3& $\{(0,0),(1,1),(2,0)\}$ & $\{(1,2),(2,3),(1,3)\}$ &$\{(2,-50)\}$ & (4,5) & Exception: InputError \\ 
 \hline
 
 
\end{tabular}
\caption{Test Cases used for Verification of Truss Tool}
\label{tbl_tc}

\end{center}		
\paragraph{Input Verification test}

\begin{enumerate}

\item{T-1: Expected Input\\}

Control: Automatic
					
Initial State: N/A
					
Input: TC1-1
					
Output: Support Reactions (25,25), Internal forces (-35,-35,25)

Test Case Derivation: Derived from existing software 2D-Truss Analysis.
					
How the test will be performed: It will be performed by test classes built with the help of Pytest
					
\item{T-2: Invalid Number of joints $N$\\}

Control: Automatic
					
Initial State: N/A
					
Input: TC2-1, TC2-2
					
Output: Exception: InputError

Test Case Derivation: N input is out of bound for 10 and 2.

How the test will be performed: It will be performed by test classes built with the help of Pytest.
\item{T-3: Invalid amount of external force $N$\\}

Control: Automatic
					
Initial State: N/A
					
Input: TC3-1, TC3-2
					
Output: Exception: InputError

Test Case Derivation: Amount of the external force/forces out of bound. 

How the test will be performed: It will be performed by test classes built with the help of Pytest.
\item{T-2: Invalid index of joints $N$\\}

Control: Automatic
					
Initial State: N/A
					
Input: TC4-1 to TC4-4
					
Output: Exception: InputError

Test Case Derivation: Any reference to joints must be in the range of 1 to N. The support Index can be zero in case of no existing support, but both indices of support cannot be zero at the same time.

How the test will be performed: It will be performed by test classes built with the help of Pytest.


\end{enumerate}

\subsubsection{Output verification}

...

\subsection{Tests for Nonfunctional Requirements}

\wss{The nonfunctional requirements for accuracy will likely just reference the
  appropriate functional tests from above.  The test cases should mention
  reporting the relative error for these tests.  Not all projects will
  necessarily have nonfunctional requirements related to accuracy}

\wss{Tests related to usability could include conducting a usability test and
  survey.  The survey will be in the Appendix.}

\wss{Static tests, review, inspections, and walkthroughs, will not follow the
format for the tests given below.}

\subsubsection{Area of Testing1}
		
\paragraph{Title for Test}

\begin{enumerate}

\item{test-id1\\}

Type: Functional, Dynamic, Manual, Static etc.
					
Initial State: 
					
Input/Condition: 
					
Output/Result: 
					
How test will be performed: 
					
\item{test-id2\\}

Type: Functional, Dynamic, Manual, Static etc.
					
Initial State: 
					
Input: 
					
Output: 
					
How test will be performed: 

\end{enumerate}

\subsubsection{Area of Testing2}

...

\subsection{Traceability Between Test Cases and Requirements}

\wss{Provide a table that shows which test cases are supporting which
  requirements.}

\section{Unit Test Description} \label{sec_unitest}

\wss{Reference your MIS (detailed design document) and explain your overall
  philosophy for test case selection.}  
\wss{This section should not be filled in until after the MIS (detailed design
  document) has been completed.}

\subsection{Unit Testing Scope}

\wss{What modules are outside of the scope.  If there are modules that are
  developed by someone else, then you would say here if you aren't planning on
  verifying them.  There may also be modules that are part of your software, but
  have a lower priority for verification than others.  If this is the case,
  explain your rationale for the ranking of module importance.}

\subsection{Tests for Functional Requirements}

\wss{Most of the verification will be through automated unit testing.  If
  appropriate specific modules can be verified by a non-testing based
  technique.  That can also be documented in this section.}

\subsubsection{Module 1}

\wss{Include a blurb here to explain why the subsections below cover the module.
  References to the MIS would be good.  You will want tests from a black box
  perspective and from a white box perspective.  Explain to the reader how the
  tests were selected.}

\begin{enumerate}

\item{test-id1\\}

Type: \wss{Functional, Dynamic, Manual, Automatic, Static etc. Most will
  be automatic}
					
Initial State: 
					
Input: 
					
Output: \wss{The expected result for the given inputs}

Test Case Derivation: \wss{Justify the expected value given in the Output field}

How test will be performed: 
					
\item{test-id2\\}

Type: \wss{Functional, Dynamic, Manual, Automatic, Static etc. Most will
  be automatic}
					
Initial State: 
					
Input: 
					
Output: \wss{The expected result for the given inputs}

Test Case Derivation: \wss{Justify the expected value given in the Output field}

How test will be performed: 

\item{...\\}
    
\end{enumerate}

\subsubsection{Module 2}

...

\subsection{Tests for Nonfunctional Requirements}

\wss{If there is a module that needs to be independently assessed for
  performance, those test cases can go here.  In some projects, planning for
  nonfunctional tests of units will not be that relevant.}

\wss{These tests may involve collecting performance data from previously
  mentioned functional tests.}

\subsubsection{Module ?}
		
\begin{enumerate}

\item{test-id1\\}

Type: \wss{Functional, Dynamic, Manual, Automatic, Static etc. Most will
  be automatic}
					
Initial State: 
					
Input/Condition: 
					
Output/Result: 
					
How test will be performed: 
					
\item{test-id2\\}

Type: Functional, Dynamic, Manual, Static etc.
					
Initial State: 
					
Input: 
					
Output: 
					
How test will be performed: 

\end{enumerate}

\subsubsection{Module ?}

...

\subsection{Traceability Between Test Cases and Modules}

\wss{Provide evidence that all of the modules have been considered.}
				
\bibliographystyle{plainnat}

\bibliography{refs/References.bib}

\newpage

\section{Appendix}

This is where you can place additional information.

\subsection{Symbolic Parameters}

The definition of the test cases will call for SYMBOLIC\_CONSTANTS.
Their values are defined in this section for easy maintenance.

\subsection{Usability Survey Questions?}

\wss{This is a section that would be appropriate for some projects.}

\newpage{}
\section*{Appendix --- Reflection}

The information in this section will be used to evaluate the team members on the
graduate attribute of Lifelong Learning.  Please answer the following questions:

\newpage{}
\section*{Appendix --- Reflection}

The information in this section will be used to evaluate the team members on the
graduate attribute of Lifelong Learning.  Please answer the following questions:

\begin{enumerate}
  \item What knowledge and skills will the team collectively need to acquire to
  successfully complete the verification and validation of your project?
  Examples of possible knowledge and skills include dynamic testing knowledge,
  static testing knowledge, specific tool usage etc.  You should look to
  identify at least one item for each team member.
  \item For each of the knowledge areas and skills identified in the previous
  question, what are at least two approaches to acquiring the knowledge or
  mastering the skill?  Of the identified approaches, which will each team
  member pursue, and why did they make this choice?
\end{enumerate}

\end{document}